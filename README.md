# Voice Pipeline Experiment

A minimal technical spike to validate the **voice â†’ LLM â†’ voice** pipeline using Google Cloud services with Application Default Credentials (ADC).

## ğŸ¯ What This Does

1. **User speaks** into microphone
2. **Google Speech-to-Text** converts speech to text
3. **Gemini API** generates a natural response
4. **Google Text-to-Speech** converts response to audio
5. **Browser plays** the audio response

## ğŸ”§ Prerequisites

1. **GCP SDK installed**
   ```bash
   # Check if installed
   gcloud --version
   ```

2. **ADC authentication configured**
   ```bash
   gcloud auth application-default login
   ```

3. **GCP Project ID**
   - Know your GCP project ID
   - Set as environment variable:
     ```bash
     export GCP_PROJECT_ID="your-project-id"
     export GCP_REGION="us-central1"  # Optional, defaults to us-central1
     ```

4. **GCP APIs enabled**
   - Speech-to-Text API
   - Text-to-Speech API
   - Vertex AI API
   - Ensure billing is enabled

## ğŸš€ Setup & Run

1. **Install dependencies**
   ```bash
   npm install
   ```

2. **Start the server**
   ```bash
   GCP_PROJECT_ID="your-project-id" node server.js
   ```

3. **Open in browser**
   ```
   http://localhost:3000
   ```

4. **Test the pipeline**
   - Click "Start Recording"
   - Speak a phrase (e.g., "Hello, how are you?")
   - Click "Stop Recording"
   - Wait for the response to play

## ğŸ“ Project Structure

```
voice-pipeline-experiment/
â”œâ”€â”€ server.js           # Express server with 3 endpoints
â”œâ”€â”€ package.json        # Dependencies
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html     # Minimal UI
â”‚   â”œâ”€â”€ app.js         # Frontend logic
â”‚   â””â”€â”€ style.css      # Styling
â””â”€â”€ README.md          # This file
```

## ğŸ”Œ API Endpoints

### POST /transcribe
- **Input**: Audio file (multipart/form-data)
- **Output**: `{ text: "transcribed text" }`
- **Uses**: Google Cloud Speech-to-Text (ADC)

### POST /chat
- **Input**: `{ text: "user message" }`
- **Output**: `{ response: "gemini response" }`
- **Uses**: Vertex AI - Gemini 2.0 Flash (ADC)

### POST /synthesize
- **Input**: `{ text: "text to speak" }`
- **Output**: `{ audio: "base64-encoded-mp3" }`
- **Uses**: Google Cloud Text-to-Speech (ADC)

## ğŸ› Troubleshooting

### "ADC not configured" error
```bash
gcloud auth application-default login
```

### "GCP_PROJECT_ID not set" error
```bash
export GCP_PROJECT_ID="your-project-id"
node server.js
```

### "API not enabled" error
- Go to [GCP Console](https://console.cloud.google.com)
- Enable Speech-to-Text API
- Enable Text-to-Speech API
- Enable Vertex AI API
- Ensure billing is enabled

### Microphone access denied
- Check browser permissions
- Use HTTPS or localhost only

## âš¡ Expected Performance

- **Round-trip time**: ~1-2 seconds
- **Transcription**: ~200-500ms
- **Gemini response**: ~500-800ms
- **TTS synthesis**: ~300-500ms
- **Network overhead**: ~200-400ms

## ğŸ¯ Success Criteria

âœ… User can speak into microphone  
âœ… Speech is correctly transcribed  
âœ… Gemini returns a natural response  
âœ… Response is spoken back clearly  
âœ… Total round-trip feels fast (~1-2s)  
âœ… Loop works consistently  

## ğŸ“ Notes

- This is a **technical validation only**, not a production system
- No memory, database, or user authentication
- Hardcoded voice settings (en-US-Neural2-F)
- Console logging for debugging
- Minimal error handling

## ğŸ”’ Authentication

**All services use Application Default Credentials (ADC):**
- Speech-to-Text: ADC âœ…
- Vertex AI (Gemini): ADC âœ…
- Text-to-Speech: ADC âœ…

No service account JSON files needed!  
No API keys needed!  

Just run: `gcloud auth application-default login`
